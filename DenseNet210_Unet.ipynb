{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "DenseNet210_Unet.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-06-18T06:49:54.730302Z",
          "iopub.execute_input": "2021-06-18T06:49:54.730610Z",
          "iopub.status.idle": "2021-06-18T06:50:00.779278Z",
          "shell.execute_reply.started": "2021-06-18T06:49:54.730545Z",
          "shell.execute_reply": "2021-06-18T06:50:00.778077Z"
        },
        "trusted": true,
        "id": "8HAhdj6jB-2O"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Conv2D , BatchNormalization , Activation , MaxPool2D , Input , Dropout , ZeroPadding2D , Conv2DTranspose , Concatenate\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "def conv_block(inputs , num_filters):\n",
        "  x = Conv2D(num_filters , 3 , padding= \"same\" )(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Conv2D(num_filters , 3 , padding= \"same\" )(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def decoder_block(inputs , skip_features , num_filters):\n",
        "\n",
        "  x = Conv2DTranspose(num_filters , (2, 2) , strides = 2 , padding = \"same\")(inputs)\n",
        "  x = Concatenate()([x , skip_features ])\n",
        "  x = conv_block(x , num_filters)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:00.783779Z",
          "iopub.execute_input": "2021-06-18T06:50:00.784116Z",
          "iopub.status.idle": "2021-06-18T06:50:00.797330Z",
          "shell.execute_reply.started": "2021-06-18T06:50:00.784082Z",
          "shell.execute_reply": "2021-06-18T06:50:00.796348Z"
        },
        "trusted": true,
        "id": "PqxcN1M1B-2a"
      },
      "source": [
        "\n",
        "# Even the skip features were extracted for the Decoder purposes to feed in the required Skip Features\n",
        "\n",
        "def build_DenseNet210_Unet(input_shape):\n",
        "\n",
        "  ##Input\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  ## Pre-Trained Encoder\n",
        "\n",
        "  encoder = DenseNet201(include_top = False , weights = \"imagenet\" , input_tensor = inputs)\n",
        "\n",
        "  # Skip Connections which are the Features and we will access these Features and Feed it in the Decoder\n",
        "  #First Feature is the input shaped image\n",
        "  s1 = encoder.get_layer(\"input_1\").output                         # 256 * 256\n",
        "\n",
        "  s2 = encoder.get_layer(\"conv1/relu\").output                       # 128 * 128 \n",
        "\n",
        "  s3 = encoder.get_layer(\"pool2_relu\").output       # 64 * 64 \n",
        "\n",
        "  s4 = encoder.get_layer(\"pool3_relu\").output       # 32 * 32\n",
        "\n",
        "  ## BottleNeck or bridge \n",
        "  b1 = encoder.get_layer(\"pool4_relu\").output       # 16 * 16\n",
        "\n",
        "  ## Decoder\n",
        "  d1 = decoder_block(b1 , s4 , 512)                                # 32 * 32 * 512 where 512 is the number of Features we extracted \n",
        "\n",
        "  d2 = decoder_block(d1 , s3 , 256)                                # 64 * 64\n",
        "\n",
        "  d3 = decoder_block(d2 , s2 , 128)                                # 128 * 128\n",
        "\n",
        "  d4 = decoder_block(d3 , s1 , 64)                                # 128 * 128\n",
        "\n",
        "  ## OUTPUT \n",
        "\n",
        "  outputs = Conv2D( 1 ,  1  ,  padding = \"same\" ,  activation = \"sigmoid\")(d4)\n",
        "\n",
        "  ## MODEL \n",
        "\n",
        "  model = Model(inputs , outputs ,  name = \"DenseNet210\")\n",
        "\n",
        "  return model\n",
        "  #encoder.summary()\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG6t4C4_B-2e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:00.802373Z",
          "iopub.execute_input": "2021-06-18T06:50:00.805028Z",
          "iopub.status.idle": "2021-06-18T06:50:08.217631Z",
          "shell.execute_reply.started": "2021-06-18T06:50:00.803062Z",
          "shell.execute_reply": "2021-06-18T06:50:08.216746Z"
        },
        "trusted": true,
        "id": "TtnLS24CB-2f",
        "outputId": "95a88f59-9d00-46be-9dad-3259af5d207d"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  input_shape = (256 , 256 , 3)\n",
        "\n",
        "  ## This Model is our Encoder and Bridge Part of our Network and we only need to Write the Decoder part only\n",
        "\n",
        "  model = build_DenseNet210_Unet(input_shape )\n",
        "  model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n74842112/74836368 [==============================] - 1s 0us/step\nModel: \"DenseNet210\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nzero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1/conv (Conv2D)             (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n__________________________________________________________________________________________________\nconv1/bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1/conv[0][0]                 \n__________________________________________________________________________________________________\nconv1/relu (Activation)         (None, 128, 128, 64) 0           conv1/bn[0][0]                   \n__________________________________________________________________________________________________\nzero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           conv1/relu[0][0]                 \n__________________________________________________________________________________________________\npool1 (MaxPooling2D)            (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 64, 64, 64)   256         pool1[0][0]                      \n__________________________________________________________________________________________________\nconv2_block1_0_relu (Activation (None, 64, 64, 64)   0           conv2_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 64, 64, 128)  8192        conv2_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 64, 64, 128)  0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_concat (Concatenat (None, 64, 64, 96)   0           pool1[0][0]                      \n                                                                 conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_bn (BatchNormali (None, 64, 64, 96)   384         conv2_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_relu (Activation (None, 64, 64, 96)   0           conv2_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 64, 64, 128)  12288       conv2_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 64, 64, 128)  0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_concat (Concatenat (None, 64, 64, 128)  0           conv2_block1_concat[0][0]        \n                                                                 conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_relu (Activation (None, 64, 64, 128)  0           conv2_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv2_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 64, 64, 128)  0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_concat (Concatenat (None, 64, 64, 160)  0           conv2_block2_concat[0][0]        \n                                                                 conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_bn (BatchNormali (None, 64, 64, 160)  640         conv2_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_relu (Activation (None, 64, 64, 160)  0           conv2_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv2_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_relu (Activation (None, 64, 64, 128)  0           conv2_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_concat (Concatenat (None, 64, 64, 192)  0           conv2_block3_concat[0][0]        \n                                                                 conv2_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_bn (BatchNormali (None, 64, 64, 192)  768         conv2_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_relu (Activation (None, 64, 64, 192)  0           conv2_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv2_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_relu (Activation (None, 64, 64, 128)  0           conv2_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_concat (Concatenat (None, 64, 64, 224)  0           conv2_block4_concat[0][0]        \n                                                                 conv2_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_bn (BatchNormali (None, 64, 64, 224)  896         conv2_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_relu (Activation (None, 64, 64, 224)  0           conv2_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv2_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_relu (Activation (None, 64, 64, 128)  0           conv2_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_concat (Concatenat (None, 64, 64, 256)  0           conv2_block5_concat[0][0]        \n                                                                 conv2_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\npool2_bn (BatchNormalization)   (None, 64, 64, 256)  1024        conv2_block6_concat[0][0]        \n__________________________________________________________________________________________________\npool2_relu (Activation)         (None, 64, 64, 256)  0           pool2_bn[0][0]                   \n__________________________________________________________________________________________________\npool2_conv (Conv2D)             (None, 64, 64, 128)  32768       pool2_relu[0][0]                 \n__________________________________________________________________________________________________\npool2_pool (AveragePooling2D)   (None, 32, 32, 128)  0           pool2_conv[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 32, 32, 128)  512         pool2_pool[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_relu (Activation (None, 32, 32, 128)  0           conv3_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv3_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_concat (Concatenat (None, 32, 32, 160)  0           pool2_pool[0][0]                 \n                                                                 conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_bn (BatchNormali (None, 32, 32, 160)  640         conv3_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_relu (Activation (None, 32, 32, 160)  0           conv3_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv3_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_concat (Concatenat (None, 32, 32, 192)  0           conv3_block1_concat[0][0]        \n                                                                 conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_bn (BatchNormali (None, 32, 32, 192)  768         conv3_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_relu (Activation (None, 32, 32, 192)  0           conv3_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv3_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_concat (Concatenat (None, 32, 32, 224)  0           conv3_block2_concat[0][0]        \n                                                                 conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_bn (BatchNormali (None, 32, 32, 224)  896         conv3_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_relu (Activation (None, 32, 32, 224)  0           conv3_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv3_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_concat (Concatenat (None, 32, 32, 256)  0           conv3_block3_concat[0][0]        \n                                                                 conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv3_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_relu (Activation (None, 32, 32, 256)  0           conv3_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_concat (Concatenat (None, 32, 32, 288)  0           conv3_block4_concat[0][0]        \n                                                                 conv3_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv3_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_relu (Activation (None, 32, 32, 288)  0           conv3_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv3_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_concat (Concatenat (None, 32, 32, 320)  0           conv3_block5_concat[0][0]        \n                                                                 conv3_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv3_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_relu (Activation (None, 32, 32, 320)  0           conv3_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv3_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_concat (Concatenat (None, 32, 32, 352)  0           conv3_block6_concat[0][0]        \n                                                                 conv3_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv3_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_relu (Activation (None, 32, 32, 352)  0           conv3_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv3_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_concat (Concatenat (None, 32, 32, 384)  0           conv3_block7_concat[0][0]        \n                                                                 conv3_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv3_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_relu (Activation (None, 32, 32, 384)  0           conv3_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv3_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_relu (Activation (None, 32, 32, 128)  0           conv3_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_concat (Concatenat (None, 32, 32, 416)  0           conv3_block8_concat[0][0]        \n                                                                 conv3_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_bn (BatchNormal (None, 32, 32, 416)  1664        conv3_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_relu (Activatio (None, 32, 32, 416)  0           conv3_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_1_conv (Conv2D)   (None, 32, 32, 128)  53248       conv3_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_concat (Concatena (None, 32, 32, 448)  0           conv3_block9_concat[0][0]        \n                                                                 conv3_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_bn (BatchNormal (None, 32, 32, 448)  1792        conv3_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_relu (Activatio (None, 32, 32, 448)  0           conv3_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_1_conv (Conv2D)   (None, 32, 32, 128)  57344       conv3_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_concat (Concatena (None, 32, 32, 480)  0           conv3_block10_concat[0][0]       \n                                                                 conv3_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_bn (BatchNormal (None, 32, 32, 480)  1920        conv3_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_relu (Activatio (None, 32, 32, 480)  0           conv3_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_1_conv (Conv2D)   (None, 32, 32, 128)  61440       conv3_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_concat (Concatena (None, 32, 32, 512)  0           conv3_block11_concat[0][0]       \n                                                                 conv3_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\npool3_bn (BatchNormalization)   (None, 32, 32, 512)  2048        conv3_block12_concat[0][0]       \n__________________________________________________________________________________________________\npool3_relu (Activation)         (None, 32, 32, 512)  0           pool3_bn[0][0]                   \n__________________________________________________________________________________________________\npool3_conv (Conv2D)             (None, 32, 32, 256)  131072      pool3_relu[0][0]                 \n__________________________________________________________________________________________________\npool3_pool (AveragePooling2D)   (None, 16, 16, 256)  0           pool3_conv[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        pool3_pool[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_relu (Activation (None, 16, 16, 256)  0           conv4_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv4_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 16, 16, 128)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_concat (Concatenat (None, 16, 16, 288)  0           pool3_pool[0][0]                 \n                                                                 conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv4_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_relu (Activation (None, 16, 16, 288)  0           conv4_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv4_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 128)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_concat (Concatenat (None, 16, 16, 320)  0           conv4_block1_concat[0][0]        \n                                                                 conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv4_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_relu (Activation (None, 16, 16, 320)  0           conv4_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv4_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 128)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_concat (Concatenat (None, 16, 16, 352)  0           conv4_block2_concat[0][0]        \n                                                                 conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv4_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_relu (Activation (None, 16, 16, 352)  0           conv4_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv4_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 128)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_concat (Concatenat (None, 16, 16, 384)  0           conv4_block3_concat[0][0]        \n                                                                 conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv4_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_relu (Activation (None, 16, 16, 384)  0           conv4_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv4_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 128)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_concat (Concatenat (None, 16, 16, 416)  0           conv4_block4_concat[0][0]        \n                                                                 conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_bn (BatchNormali (None, 16, 16, 416)  1664        conv4_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_relu (Activation (None, 16, 16, 416)  0           conv4_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 128)  53248       conv4_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 128)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_concat (Concatenat (None, 16, 16, 448)  0           conv4_block5_concat[0][0]        \n                                                                 conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_bn (BatchNormali (None, 16, 16, 448)  1792        conv4_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_relu (Activation (None, 16, 16, 448)  0           conv4_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_1_conv (Conv2D)    (None, 16, 16, 128)  57344       conv4_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_relu (Activation (None, 16, 16, 128)  0           conv4_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_concat (Concatenat (None, 16, 16, 480)  0           conv4_block6_concat[0][0]        \n                                                                 conv4_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_bn (BatchNormali (None, 16, 16, 480)  1920        conv4_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_relu (Activation (None, 16, 16, 480)  0           conv4_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_1_conv (Conv2D)    (None, 16, 16, 128)  61440       conv4_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_relu (Activation (None, 16, 16, 128)  0           conv4_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_concat (Concatenat (None, 16, 16, 512)  0           conv4_block7_concat[0][0]        \n                                                                 conv4_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv4_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_relu (Activation (None, 16, 16, 512)  0           conv4_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_1_conv (Conv2D)    (None, 16, 16, 128)  65536       conv4_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_relu (Activation (None, 16, 16, 128)  0           conv4_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_concat (Concatenat (None, 16, 16, 544)  0           conv4_block8_concat[0][0]        \n                                                                 conv4_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_bn (BatchNormal (None, 16, 16, 544)  2176        conv4_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_relu (Activatio (None, 16, 16, 544)  0           conv4_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_1_conv (Conv2D)   (None, 16, 16, 128)  69632       conv4_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_concat (Concatena (None, 16, 16, 576)  0           conv4_block9_concat[0][0]        \n                                                                 conv4_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_bn (BatchNormal (None, 16, 16, 576)  2304        conv4_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_relu (Activatio (None, 16, 16, 576)  0           conv4_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_1_conv (Conv2D)   (None, 16, 16, 128)  73728       conv4_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_concat (Concatena (None, 16, 16, 608)  0           conv4_block10_concat[0][0]       \n                                                                 conv4_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_bn (BatchNormal (None, 16, 16, 608)  2432        conv4_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_relu (Activatio (None, 16, 16, 608)  0           conv4_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_1_conv (Conv2D)   (None, 16, 16, 128)  77824       conv4_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_concat (Concatena (None, 16, 16, 640)  0           conv4_block11_concat[0][0]       \n                                                                 conv4_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_bn (BatchNormal (None, 16, 16, 640)  2560        conv4_block12_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_relu (Activatio (None, 16, 16, 640)  0           conv4_block13_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_1_conv (Conv2D)   (None, 16, 16, 128)  81920       conv4_block13_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_concat (Concatena (None, 16, 16, 672)  0           conv4_block12_concat[0][0]       \n                                                                 conv4_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_bn (BatchNormal (None, 16, 16, 672)  2688        conv4_block13_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_relu (Activatio (None, 16, 16, 672)  0           conv4_block14_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_1_conv (Conv2D)   (None, 16, 16, 128)  86016       conv4_block14_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_concat (Concatena (None, 16, 16, 704)  0           conv4_block13_concat[0][0]       \n                                                                 conv4_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_bn (BatchNormal (None, 16, 16, 704)  2816        conv4_block14_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_relu (Activatio (None, 16, 16, 704)  0           conv4_block15_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_1_conv (Conv2D)   (None, 16, 16, 128)  90112       conv4_block15_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_concat (Concatena (None, 16, 16, 736)  0           conv4_block14_concat[0][0]       \n                                                                 conv4_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_bn (BatchNormal (None, 16, 16, 736)  2944        conv4_block15_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_relu (Activatio (None, 16, 16, 736)  0           conv4_block16_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_1_conv (Conv2D)   (None, 16, 16, 128)  94208       conv4_block16_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_concat (Concatena (None, 16, 16, 768)  0           conv4_block15_concat[0][0]       \n                                                                 conv4_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_bn (BatchNormal (None, 16, 16, 768)  3072        conv4_block16_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_relu (Activatio (None, 16, 16, 768)  0           conv4_block17_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_1_conv (Conv2D)   (None, 16, 16, 128)  98304       conv4_block17_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block17_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block17_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block17_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_concat (Concatena (None, 16, 16, 800)  0           conv4_block16_concat[0][0]       \n                                                                 conv4_block17_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_bn (BatchNormal (None, 16, 16, 800)  3200        conv4_block17_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_relu (Activatio (None, 16, 16, 800)  0           conv4_block18_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_1_conv (Conv2D)   (None, 16, 16, 128)  102400      conv4_block18_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block18_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block18_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block18_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_concat (Concatena (None, 16, 16, 832)  0           conv4_block17_concat[0][0]       \n                                                                 conv4_block18_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_bn (BatchNormal (None, 16, 16, 832)  3328        conv4_block18_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_relu (Activatio (None, 16, 16, 832)  0           conv4_block19_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_1_conv (Conv2D)   (None, 16, 16, 128)  106496      conv4_block19_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block19_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block19_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block19_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_concat (Concatena (None, 16, 16, 864)  0           conv4_block18_concat[0][0]       \n                                                                 conv4_block19_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_bn (BatchNormal (None, 16, 16, 864)  3456        conv4_block19_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_relu (Activatio (None, 16, 16, 864)  0           conv4_block20_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_1_conv (Conv2D)   (None, 16, 16, 128)  110592      conv4_block20_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block20_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block20_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block20_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_concat (Concatena (None, 16, 16, 896)  0           conv4_block19_concat[0][0]       \n                                                                 conv4_block20_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_bn (BatchNormal (None, 16, 16, 896)  3584        conv4_block20_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_relu (Activatio (None, 16, 16, 896)  0           conv4_block21_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_1_conv (Conv2D)   (None, 16, 16, 128)  114688      conv4_block21_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_concat (Concatena (None, 16, 16, 928)  0           conv4_block20_concat[0][0]       \n                                                                 conv4_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_bn (BatchNormal (None, 16, 16, 928)  3712        conv4_block21_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_relu (Activatio (None, 16, 16, 928)  0           conv4_block22_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_1_conv (Conv2D)   (None, 16, 16, 128)  118784      conv4_block22_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_concat (Concatena (None, 16, 16, 960)  0           conv4_block21_concat[0][0]       \n                                                                 conv4_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_bn (BatchNormal (None, 16, 16, 960)  3840        conv4_block22_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_relu (Activatio (None, 16, 16, 960)  0           conv4_block23_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_1_conv (Conv2D)   (None, 16, 16, 128)  122880      conv4_block23_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_concat (Concatena (None, 16, 16, 992)  0           conv4_block22_concat[0][0]       \n                                                                 conv4_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_bn (BatchNormal (None, 16, 16, 992)  3968        conv4_block23_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_relu (Activatio (None, 16, 16, 992)  0           conv4_block24_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_1_conv (Conv2D)   (None, 16, 16, 128)  126976      conv4_block24_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_concat (Concatena (None, 16, 16, 1024) 0           conv4_block23_concat[0][0]       \n                                                                 conv4_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_0_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block24_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_0_relu (Activatio (None, 16, 16, 1024) 0           conv4_block25_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block25_1_conv (Conv2D)   (None, 16, 16, 128)  131072      conv4_block25_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block25_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block25_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block25_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block25_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_concat (Concatena (None, 16, 16, 1056) 0           conv4_block24_concat[0][0]       \n                                                                 conv4_block25_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_0_bn (BatchNormal (None, 16, 16, 1056) 4224        conv4_block25_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_0_relu (Activatio (None, 16, 16, 1056) 0           conv4_block26_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block26_1_conv (Conv2D)   (None, 16, 16, 128)  135168      conv4_block26_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block26_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block26_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block26_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block26_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_concat (Concatena (None, 16, 16, 1088) 0           conv4_block25_concat[0][0]       \n                                                                 conv4_block26_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_0_bn (BatchNormal (None, 16, 16, 1088) 4352        conv4_block26_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_0_relu (Activatio (None, 16, 16, 1088) 0           conv4_block27_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block27_1_conv (Conv2D)   (None, 16, 16, 128)  139264      conv4_block27_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block27_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block27_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block27_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block27_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_concat (Concatena (None, 16, 16, 1120) 0           conv4_block26_concat[0][0]       \n                                                                 conv4_block27_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_0_bn (BatchNormal (None, 16, 16, 1120) 4480        conv4_block27_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_0_relu (Activatio (None, 16, 16, 1120) 0           conv4_block28_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block28_1_conv (Conv2D)   (None, 16, 16, 128)  143360      conv4_block28_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block28_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block28_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block28_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block28_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_concat (Concatena (None, 16, 16, 1152) 0           conv4_block27_concat[0][0]       \n                                                                 conv4_block28_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_0_bn (BatchNormal (None, 16, 16, 1152) 4608        conv4_block28_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_0_relu (Activatio (None, 16, 16, 1152) 0           conv4_block29_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block29_1_conv (Conv2D)   (None, 16, 16, 128)  147456      conv4_block29_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block29_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block29_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block29_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block29_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_concat (Concatena (None, 16, 16, 1184) 0           conv4_block28_concat[0][0]       \n                                                                 conv4_block29_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_0_bn (BatchNormal (None, 16, 16, 1184) 4736        conv4_block29_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_0_relu (Activatio (None, 16, 16, 1184) 0           conv4_block30_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block30_1_conv (Conv2D)   (None, 16, 16, 128)  151552      conv4_block30_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block30_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block30_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block30_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block30_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_concat (Concatena (None, 16, 16, 1216) 0           conv4_block29_concat[0][0]       \n                                                                 conv4_block30_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_0_bn (BatchNormal (None, 16, 16, 1216) 4864        conv4_block30_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_0_relu (Activatio (None, 16, 16, 1216) 0           conv4_block31_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block31_1_conv (Conv2D)   (None, 16, 16, 128)  155648      conv4_block31_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block31_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block31_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block31_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block31_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_concat (Concatena (None, 16, 16, 1248) 0           conv4_block30_concat[0][0]       \n                                                                 conv4_block31_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_0_bn (BatchNormal (None, 16, 16, 1248) 4992        conv4_block31_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_0_relu (Activatio (None, 16, 16, 1248) 0           conv4_block32_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block32_1_conv (Conv2D)   (None, 16, 16, 128)  159744      conv4_block32_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block32_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block32_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block32_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block32_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_concat (Concatena (None, 16, 16, 1280) 0           conv4_block31_concat[0][0]       \n                                                                 conv4_block32_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_0_bn (BatchNormal (None, 16, 16, 1280) 5120        conv4_block32_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_0_relu (Activatio (None, 16, 16, 1280) 0           conv4_block33_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block33_1_conv (Conv2D)   (None, 16, 16, 128)  163840      conv4_block33_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block33_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block33_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block33_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block33_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_concat (Concatena (None, 16, 16, 1312) 0           conv4_block32_concat[0][0]       \n                                                                 conv4_block33_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_0_bn (BatchNormal (None, 16, 16, 1312) 5248        conv4_block33_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_0_relu (Activatio (None, 16, 16, 1312) 0           conv4_block34_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block34_1_conv (Conv2D)   (None, 16, 16, 128)  167936      conv4_block34_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block34_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block34_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block34_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block34_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_concat (Concatena (None, 16, 16, 1344) 0           conv4_block33_concat[0][0]       \n                                                                 conv4_block34_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_0_bn (BatchNormal (None, 16, 16, 1344) 5376        conv4_block34_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_0_relu (Activatio (None, 16, 16, 1344) 0           conv4_block35_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block35_1_conv (Conv2D)   (None, 16, 16, 128)  172032      conv4_block35_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block35_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block35_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block35_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block35_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_concat (Concatena (None, 16, 16, 1376) 0           conv4_block34_concat[0][0]       \n                                                                 conv4_block35_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_0_bn (BatchNormal (None, 16, 16, 1376) 5504        conv4_block35_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_0_relu (Activatio (None, 16, 16, 1376) 0           conv4_block36_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block36_1_conv (Conv2D)   (None, 16, 16, 128)  176128      conv4_block36_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block36_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block36_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block36_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block36_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_concat (Concatena (None, 16, 16, 1408) 0           conv4_block35_concat[0][0]       \n                                                                 conv4_block36_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_0_bn (BatchNormal (None, 16, 16, 1408) 5632        conv4_block36_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_0_relu (Activatio (None, 16, 16, 1408) 0           conv4_block37_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block37_1_conv (Conv2D)   (None, 16, 16, 128)  180224      conv4_block37_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block37_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block37_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block37_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block37_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_concat (Concatena (None, 16, 16, 1440) 0           conv4_block36_concat[0][0]       \n                                                                 conv4_block37_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_0_bn (BatchNormal (None, 16, 16, 1440) 5760        conv4_block37_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_0_relu (Activatio (None, 16, 16, 1440) 0           conv4_block38_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block38_1_conv (Conv2D)   (None, 16, 16, 128)  184320      conv4_block38_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block38_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block38_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block38_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block38_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_concat (Concatena (None, 16, 16, 1472) 0           conv4_block37_concat[0][0]       \n                                                                 conv4_block38_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_0_bn (BatchNormal (None, 16, 16, 1472) 5888        conv4_block38_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_0_relu (Activatio (None, 16, 16, 1472) 0           conv4_block39_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block39_1_conv (Conv2D)   (None, 16, 16, 128)  188416      conv4_block39_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block39_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block39_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block39_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block39_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_concat (Concatena (None, 16, 16, 1504) 0           conv4_block38_concat[0][0]       \n                                                                 conv4_block39_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_0_bn (BatchNormal (None, 16, 16, 1504) 6016        conv4_block39_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_0_relu (Activatio (None, 16, 16, 1504) 0           conv4_block40_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block40_1_conv (Conv2D)   (None, 16, 16, 128)  192512      conv4_block40_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block40_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block40_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block40_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block40_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_concat (Concatena (None, 16, 16, 1536) 0           conv4_block39_concat[0][0]       \n                                                                 conv4_block40_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_0_bn (BatchNormal (None, 16, 16, 1536) 6144        conv4_block40_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_0_relu (Activatio (None, 16, 16, 1536) 0           conv4_block41_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block41_1_conv (Conv2D)   (None, 16, 16, 128)  196608      conv4_block41_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block41_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block41_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block41_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block41_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_concat (Concatena (None, 16, 16, 1568) 0           conv4_block40_concat[0][0]       \n                                                                 conv4_block41_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_0_bn (BatchNormal (None, 16, 16, 1568) 6272        conv4_block41_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_0_relu (Activatio (None, 16, 16, 1568) 0           conv4_block42_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block42_1_conv (Conv2D)   (None, 16, 16, 128)  200704      conv4_block42_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block42_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block42_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block42_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block42_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_concat (Concatena (None, 16, 16, 1600) 0           conv4_block41_concat[0][0]       \n                                                                 conv4_block42_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_0_bn (BatchNormal (None, 16, 16, 1600) 6400        conv4_block42_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_0_relu (Activatio (None, 16, 16, 1600) 0           conv4_block43_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block43_1_conv (Conv2D)   (None, 16, 16, 128)  204800      conv4_block43_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block43_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block43_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block43_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block43_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_concat (Concatena (None, 16, 16, 1632) 0           conv4_block42_concat[0][0]       \n                                                                 conv4_block43_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_0_bn (BatchNormal (None, 16, 16, 1632) 6528        conv4_block43_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_0_relu (Activatio (None, 16, 16, 1632) 0           conv4_block44_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block44_1_conv (Conv2D)   (None, 16, 16, 128)  208896      conv4_block44_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block44_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block44_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block44_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block44_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_concat (Concatena (None, 16, 16, 1664) 0           conv4_block43_concat[0][0]       \n                                                                 conv4_block44_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_0_bn (BatchNormal (None, 16, 16, 1664) 6656        conv4_block44_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_0_relu (Activatio (None, 16, 16, 1664) 0           conv4_block45_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block45_1_conv (Conv2D)   (None, 16, 16, 128)  212992      conv4_block45_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block45_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block45_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block45_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block45_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_concat (Concatena (None, 16, 16, 1696) 0           conv4_block44_concat[0][0]       \n                                                                 conv4_block45_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_0_bn (BatchNormal (None, 16, 16, 1696) 6784        conv4_block45_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_0_relu (Activatio (None, 16, 16, 1696) 0           conv4_block46_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block46_1_conv (Conv2D)   (None, 16, 16, 128)  217088      conv4_block46_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block46_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block46_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block46_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block46_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_concat (Concatena (None, 16, 16, 1728) 0           conv4_block45_concat[0][0]       \n                                                                 conv4_block46_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_0_bn (BatchNormal (None, 16, 16, 1728) 6912        conv4_block46_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_0_relu (Activatio (None, 16, 16, 1728) 0           conv4_block47_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block47_1_conv (Conv2D)   (None, 16, 16, 128)  221184      conv4_block47_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block47_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block47_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block47_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block47_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_concat (Concatena (None, 16, 16, 1760) 0           conv4_block46_concat[0][0]       \n                                                                 conv4_block47_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_0_bn (BatchNormal (None, 16, 16, 1760) 7040        conv4_block47_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_0_relu (Activatio (None, 16, 16, 1760) 0           conv4_block48_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block48_1_conv (Conv2D)   (None, 16, 16, 128)  225280      conv4_block48_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block48_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block48_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block48_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block48_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_concat (Concatena (None, 16, 16, 1792) 0           conv4_block47_concat[0][0]       \n                                                                 conv4_block48_2_conv[0][0]       \n__________________________________________________________________________________________________\npool4_bn (BatchNormalization)   (None, 16, 16, 1792) 7168        conv4_block48_concat[0][0]       \n__________________________________________________________________________________________________\npool4_relu (Activation)         (None, 16, 16, 1792) 0           pool4_bn[0][0]                   \n__________________________________________________________________________________________________\nconv2d_transpose (Conv2DTranspo (None, 32, 32, 512)  3670528     pool4_relu[0][0]                 \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 32, 32, 1024) 0           conv2d_transpose[0][0]           \n                                                                 pool3_relu[0][0]                 \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 32, 32, 512)  4719104     concatenate[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 32, 32, 512)  2048        conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 32, 32, 512)  0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 32, 32, 512)  0           activation[0][0]                 \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 512)  2359808     dropout[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 512)  2048        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 32, 512)  0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 32, 32, 512)  0           activation_1[0][0]               \n__________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  524544      dropout_1[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_1[0][0]         \n                                                                 pool2_relu[0][0]                 \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 64, 64, 256)  1024        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 64, 64, 256)  0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 64, 64, 256)  0           activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 64, 64, 256)  590080      dropout_2[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 64, 64, 256)  1024        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 64, 64, 256)  0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 64, 64, 256)  0           activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 131200      dropout_3[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 128, 128, 192 0           conv2d_transpose_2[0][0]         \n                                                                 conv1/relu[0][0]                 \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 128, 128, 128 221312      concatenate_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 128, 128, 128 0           activation_4[0][0]               \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 128, 128, 128 147584      dropout_4[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 128, 128, 128 0           activation_5[0][0]               \n__________________________________________________________________________________________________\nconv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 32832       dropout_5[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 256, 256, 67) 0           conv2d_transpose_3[0][0]         \n                                                                 input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 256, 256, 64) 38656       concatenate_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 256, 256, 64) 256         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 256, 256, 64) 0           activation_6[0][0]               \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 256, 256, 64) 36928       dropout_6[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 256, 256, 64) 256         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 256, 256, 64) 0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 256, 256, 64) 0           activation_7[0][0]               \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 256, 256, 1)  65          dropout_7[0][0]                  \n==================================================================================================\nTotal params: 23,293,057\nTrainable params: 23,161,281\nNon-trainable params: 131,776\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:08.219331Z",
          "iopub.execute_input": "2021-06-18T06:50:08.219679Z",
          "iopub.status.idle": "2021-06-18T06:50:09.367885Z",
          "shell.execute_reply.started": "2021-06-18T06:50:08.219640Z",
          "shell.execute_reply": "2021-06-18T06:50:09.367016Z"
        },
        "trusted": true,
        "id": "zAqPVy7GB-2t",
        "outputId": "0f8050e3-ff20-480b-fb9a-1ea0bbcc6966"
      },
      "source": [
        "def load_data(paths , split = 0.15):\n",
        "  images = []\n",
        "  masks = []\n",
        "  numImages = 0\n",
        "  numMasks = 0\n",
        "\n",
        "  for path in paths:\n",
        "    \n",
        "        \n",
        "    images.extend(sorted(glob(os.path.join(path , \"images/*\"))))\n",
        "    masks.extend(sorted(glob(os.path.join(path , \"label/*\"))))\n",
        "    if \"training\" in path:\n",
        "      for i in [\"00\", \"01\" , \"02\" , \"03\" , \"04\" , \"05\" , \"07\", \"08\" , \"09\" , \"10\" , \"11\" , \"12\" , \"13\" , \"14\" , \"16\" , \"17\" , \"18\" , \"19\" , \"21\" , \"22\" , \"24\" , \"26\" , \"27\" ]:\n",
        "        images.remove(\"../input/chagas/ChagasTraining/training-20210525T143718Z-001/training/images/i8{}.xml\".format(i))\n",
        "\n",
        "      n = \"training\"\n",
        "    if \"Test\" in path:\n",
        "      n= \"Test\"\n",
        "    if \"Val\" in path:\n",
        "\n",
        "      n= \"Validation\"\n",
        "\n",
        "    print(\"{}PathImagesAre:\".format(n),len(images) - numImages)\n",
        "    print(\"{}PathImagesAre:\".format(n),len(masks) - numMasks)\n",
        "\n",
        "    numImages = len(images)\n",
        "    numMasks = len(masks)\n",
        "\n",
        "  total_size = len(images)\n",
        "  valid_size = int(split * total_size)\n",
        "  test_size = int(split * total_size)\n",
        "  print(\"Number of images in Total , Validation images and Test Images : \" , total_size , valid_size ,test_size  )\n",
        "\n",
        "  train_x , test_x = train_test_split(images , test_size = test_size , random_state = 42 )\n",
        "  train_y , test_y = train_test_split(masks , test_size = test_size , random_state = 42 )\n",
        "\n",
        "  train_x , valid_x = train_test_split(train_x , test_size = valid_size , random_state = 42 )\n",
        "  train_y , valid_y = train_test_split(train_y , test_size = valid_size , random_state = 42 )\n",
        "\n",
        "  return (train_x , train_y) , (valid_x , valid_y ) , (test_x , test_y) \n",
        "\n",
        "def read_image(path):\n",
        "  path = path.decode()\n",
        "  x = cv2.imread(path , cv2.IMREAD_COLOR)\n",
        "  x = cv2.resize(x , (256 , 256))\n",
        "  x = x/255.0\n",
        "  #Size is 256 * 256 * 3\n",
        "\n",
        "  return x\n",
        "\n",
        "def read_mask(path):\n",
        "  path = path.decode()\n",
        "  x = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n",
        "  x = cv2.resize(x , (256 , 256))\n",
        "  x = x/255.0\n",
        "  \n",
        "  #Size is 256 * 256\n",
        "  x = np.expand_dims(x , axis = -1)\n",
        "  #Size becames 256 * 256 * 1\n",
        "\n",
        "  return x\n",
        "\n",
        "def tf_parse(imagepath , maskpath):\n",
        "  def _parse(imagepath , maskpath):\n",
        "    x = read_image(imagepath)\n",
        "    y = read_mask(maskpath)\n",
        "\n",
        "    return x , y\n",
        "\n",
        "  x , y = tf.numpy_function(_parse , [imagepath , maskpath] , [tf.float64 , tf.float64] )\n",
        "  x.set_shape([256 , 256 , 3])\n",
        "  y.set_shape([256, 256, 1])\n",
        "\n",
        "  return x , y \n",
        "\n",
        "\n",
        "def tf_dataset( imagepath , maskpath , batch = 8):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((imagepath , maskpath))\n",
        "  dataset = dataset.map(tf_parse)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  paths = [\"../input/chagas/ChagasTraining/training-20210525T143718Z-001/training\" , \"../input/chagas/ChagasTest/Test\", \"../input/chagas/ChagasValidation/Validation\"] \n",
        "  (train_x , train_y) , (valid_x , valid_y ) , (test_x , test_y)  =   load_data(paths)\n",
        "\n",
        "  print(\"Number of images in Train , Validation images and Test Images : \" ,len(train_x) , len(valid_x ) , len(test_x) )\n",
        "\n",
        "  ds = tf_dataset(test_x , test_y)\n",
        "  for x, y in ds:\n",
        "    \n",
        "    print(x.shape , y.shape)\n",
        "    break\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "trainingPathImagesAre: 600\ntrainingPathImagesAre: 600\nTestPathImagesAre: 200\nTestPathImagesAre: 200\nValidationPathImagesAre: 200\nValidationPathImagesAre: 200\nNumber of images in Total , Validation images and Test Images :  1000 150 150\nNumber of images in Train , Validation images and Test Images :  700 150 150\n(8, 256, 256, 3) (8, 256, 256, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:09.368968Z",
          "iopub.execute_input": "2021-06-18T06:50:09.369222Z",
          "iopub.status.idle": "2021-06-18T06:50:09.376673Z",
          "shell.execute_reply.started": "2021-06-18T06:50:09.369198Z",
          "shell.execute_reply": "2021-06-18T06:50:09.375884Z"
        },
        "trusted": true,
        "id": "yF76PgUQB-2v"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:09.378047Z",
          "iopub.execute_input": "2021-06-18T06:50:09.378506Z",
          "iopub.status.idle": "2021-06-18T06:50:09.386259Z",
          "shell.execute_reply.started": "2021-06-18T06:50:09.378470Z",
          "shell.execute_reply": "2021-06-18T06:50:09.385170Z"
        },
        "trusted": true,
        "id": "sdqpZGHWB-2y"
      },
      "source": [
        "# Train \n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
        "from tensorflow.keras.metrics import Recall , Precision \n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:09.387390Z",
          "iopub.execute_input": "2021-06-18T06:50:09.387822Z",
          "iopub.status.idle": "2021-06-18T06:50:17.623248Z",
          "shell.execute_reply.started": "2021-06-18T06:50:09.387788Z",
          "shell.execute_reply": "2021-06-18T06:50:17.622324Z"
        },
        "trusted": true,
        "id": "ebHHKz4uB-20",
        "outputId": "74347e29-f72d-40cb-8f62-48243614f45f"
      },
      "source": [
        "pip install segmentation_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 1.7 MB/s eta 0:00:01\n\u001b[?25hCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.4.8)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.4)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.2.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:17.626993Z",
          "iopub.execute_input": "2021-06-18T06:50:17.627272Z",
          "iopub.status.idle": "2021-06-18T06:50:17.636680Z",
          "shell.execute_reply.started": "2021-06-18T06:50:17.627241Z",
          "shell.execute_reply": "2021-06-18T06:50:17.635689Z"
        },
        "trusted": true,
        "id": "IHQOs78SB-24",
        "outputId": "2bb3f94f-2386-47bb-fed3-34cc4e8d0048"
      },
      "source": [
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "env: SM_FRAMEWORK=tf.keras\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T06:50:17.638432Z",
          "iopub.execute_input": "2021-06-18T06:50:17.638895Z",
          "iopub.status.idle": "2021-06-18T07:18:42.066865Z",
          "shell.execute_reply.started": "2021-06-18T06:50:17.638846Z",
          "shell.execute_reply": "2021-06-18T07:18:42.065957Z"
        },
        "trusted": true,
        "id": "MFmThbXRB-27",
        "outputId": "f67063c7-7355-4f22-9ff8-94d705017cc5"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from segmentation_models.losses import bce_jaccard_loss\n",
        "    from segmentation_models.metrics import iou_score\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "    #HYPERPARAMETER\n",
        "\n",
        "\n",
        "    batch = 8\n",
        "    lr = 1e-4\n",
        "    epochs = 60\n",
        "    opt = tf.keras.optimizers.Adam(lr)\n",
        "    metrics = [\"acc\" , Recall() , Precision() , iou_score]\n",
        "    #Data\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n",
        "\n",
        "    #model = build_model()\n",
        "    #model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(loss=bce_jaccard_loss, optimizer=opt, metrics=metrics)\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"files/model.h5\"),\n",
        "        ReduceLROnPlateau(monitor='val_iou', factor=0.1, patience=4),\n",
        "        CSVLogger(\"../data.csv\"),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor='val_iou', patience=20, restore_best_weights=False)\n",
        "    ]\n",
        "    #Number Of Batches\n",
        "    train_steps = len(train_x)//batch\n",
        "    valid_steps = len(valid_x)//batch\n",
        "\n",
        "    if len(train_x) % batch != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch != 0:\n",
        "        valid_steps += 1\n",
        "\n",
        "    model.fit(train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks,\n",
        "        shuffle = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Segmentation Models: using `tf.keras` framework.\nEpoch 1/60\n88/88 [==============================] - 57s 417ms/step - loss: 1.5851 - acc: 0.7169 - recall: 0.3345 - precision: 0.0196 - iou_score: 0.0149 - val_loss: 1.2414 - val_acc: 0.9840 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_iou_score: 0.0124\nEpoch 2/60\n88/88 [==============================] - 26s 295ms/step - loss: 1.1136 - acc: 0.9829 - recall: 0.6863 - precision: 0.5779 - iou_score: 0.0599 - val_loss: 1.4558 - val_acc: 0.9771 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_iou_score: 0.0103\nEpoch 3/60\n88/88 [==============================] - 26s 293ms/step - loss: 1.0168 - acc: 0.9860 - recall: 0.8308 - precision: 0.6874 - iou_score: 0.1031 - val_loss: 1.1499 - val_acc: 0.9833 - val_recall: 3.3430e-05 - val_precision: 3.3781e-04 - val_iou_score: 0.0099\nEpoch 4/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.9517 - acc: 0.9875 - recall: 0.8840 - precision: 0.7443 - iou_score: 0.1393 - val_loss: 1.0978 - val_acc: 0.9844 - val_recall: 0.0387 - val_precision: 0.4766 - val_iou_score: 0.0229\nEpoch 5/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.8986 - acc: 0.9884 - recall: 0.8957 - precision: 0.7812 - iou_score: 0.1740 - val_loss: 0.9854 - val_acc: 0.9870 - val_recall: 0.3429 - val_precision: 0.8720 - val_iou_score: 0.1241\nEpoch 6/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.8498 - acc: 0.9892 - recall: 0.8929 - precision: 0.8161 - iou_score: 0.2104 - val_loss: 0.7755 - val_acc: 0.9873 - val_recall: 0.7866 - val_precision: 0.7593 - val_iou_score: 0.2807\nEpoch 7/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.8032 - acc: 0.9891 - recall: 0.8972 - precision: 0.8163 - iou_score: 0.2486 - val_loss: 0.7374 - val_acc: 0.9879 - val_recall: 0.7512 - val_precision: 0.7953 - val_iou_score: 0.3073\nEpoch 8/60\n88/88 [==============================] - 26s 293ms/step - loss: 0.7572 - acc: 0.9891 - recall: 0.9012 - precision: 0.8154 - iou_score: 0.2881 - val_loss: 0.8118 - val_acc: 0.9884 - val_recall: 0.5989 - val_precision: 0.8714 - val_iou_score: 0.2699\nEpoch 9/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.7001 - acc: 0.9901 - recall: 0.8933 - precision: 0.8607 - iou_score: 0.3369 - val_loss: 0.7335 - val_acc: 0.9889 - val_recall: 0.6185 - val_precision: 0.9053 - val_iou_score: 0.3053\nEpoch 10/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.6470 - acc: 0.9904 - recall: 0.8873 - precision: 0.8817 - iou_score: 0.3845 - val_loss: 0.7009 - val_acc: 0.9892 - val_recall: 0.6475 - val_precision: 0.8996 - val_iou_score: 0.3346\nEpoch 11/60\n88/88 [==============================] - 26s 299ms/step - loss: 0.5945 - acc: 0.9907 - recall: 0.8837 - precision: 0.8963 - iou_score: 0.4329 - val_loss: 0.6434 - val_acc: 0.9882 - val_recall: 0.7944 - val_precision: 0.8031 - val_iou_score: 0.3961\nEpoch 12/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.5416 - acc: 0.9909 - recall: 0.8834 - precision: 0.9091 - iou_score: 0.4820 - val_loss: 0.5958 - val_acc: 0.9890 - val_recall: 0.7615 - val_precision: 0.8518 - val_iou_score: 0.4374\nEpoch 13/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.4996 - acc: 0.9909 - recall: 0.8783 - precision: 0.9102 - iou_score: 0.5221 - val_loss: 0.5678 - val_acc: 0.9891 - val_recall: 0.7177 - val_precision: 0.8643 - val_iou_score: 0.4643\nEpoch 14/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.4652 - acc: 0.9910 - recall: 0.8663 - precision: 0.9133 - iou_score: 0.5550 - val_loss: 0.5532 - val_acc: 0.9890 - val_recall: 0.7067 - val_precision: 0.8602 - val_iou_score: 0.4804\nEpoch 15/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.4232 - acc: 0.9911 - recall: 0.8716 - precision: 0.9233 - iou_score: 0.5950 - val_loss: 0.5141 - val_acc: 0.9888 - val_recall: 0.7418 - val_precision: 0.8441 - val_iou_score: 0.5204\nEpoch 16/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.3832 - acc: 0.9914 - recall: 0.8728 - precision: 0.9386 - iou_score: 0.6332 - val_loss: 0.5089 - val_acc: 0.9890 - val_recall: 0.7052 - val_precision: 0.8661 - val_iou_score: 0.5274\nEpoch 17/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.3546 - acc: 0.9915 - recall: 0.8722 - precision: 0.9424 - iou_score: 0.6610 - val_loss: 0.4551 - val_acc: 0.9887 - val_recall: 0.7935 - val_precision: 0.8330 - val_iou_score: 0.5801\nEpoch 18/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.3311 - acc: 0.9915 - recall: 0.8740 - precision: 0.9442 - iou_score: 0.6840 - val_loss: 0.4513 - val_acc: 0.9892 - val_recall: 0.7199 - val_precision: 0.8791 - val_iou_score: 0.5811\nEpoch 19/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.3125 - acc: 0.9915 - recall: 0.8762 - precision: 0.9438 - iou_score: 0.7022 - val_loss: 0.4359 - val_acc: 0.9885 - val_recall: 0.7891 - val_precision: 0.8210 - val_iou_score: 0.6003\nEpoch 20/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.2986 - acc: 0.9915 - recall: 0.8761 - precision: 0.9442 - iou_score: 0.7158 - val_loss: 0.4070 - val_acc: 0.9892 - val_recall: 0.7531 - val_precision: 0.8672 - val_iou_score: 0.6249\nEpoch 21/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.2803 - acc: 0.9916 - recall: 0.8824 - precision: 0.9469 - iou_score: 0.7335 - val_loss: 0.4899 - val_acc: 0.9884 - val_recall: 0.6704 - val_precision: 0.8507 - val_iou_score: 0.5510\nEpoch 22/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.2691 - acc: 0.9917 - recall: 0.8741 - precision: 0.9529 - iou_score: 0.7444 - val_loss: 0.4182 - val_acc: 0.9893 - val_recall: 0.7159 - val_precision: 0.8825 - val_iou_score: 0.6161\nEpoch 23/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.2546 - acc: 0.9918 - recall: 0.8763 - precision: 0.9575 - iou_score: 0.7584 - val_loss: 0.4354 - val_acc: 0.9895 - val_recall: 0.6444 - val_precision: 0.9254 - val_iou_score: 0.5989\nEpoch 24/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.2478 - acc: 0.9918 - recall: 0.8660 - precision: 0.9622 - iou_score: 0.7650 - val_loss: 0.4431 - val_acc: 0.9895 - val_recall: 0.6327 - val_precision: 0.9323 - val_iou_score: 0.5922\nEpoch 25/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.2376 - acc: 0.9918 - recall: 0.8644 - precision: 0.9662 - iou_score: 0.7746 - val_loss: 0.3902 - val_acc: 0.9893 - val_recall: 0.7471 - val_precision: 0.8744 - val_iou_score: 0.6436\nEpoch 26/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.2218 - acc: 0.9919 - recall: 0.8723 - precision: 0.9691 - iou_score: 0.7897 - val_loss: 0.4058 - val_acc: 0.9891 - val_recall: 0.7215 - val_precision: 0.8702 - val_iou_score: 0.6297\nEpoch 27/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.2269 - acc: 0.9918 - recall: 0.8682 - precision: 0.9632 - iou_score: 0.7855 - val_loss: 0.4413 - val_acc: 0.9892 - val_recall: 0.6671 - val_precision: 0.9014 - val_iou_score: 0.5978\nEpoch 28/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.2132 - acc: 0.9919 - recall: 0.8746 - precision: 0.9686 - iou_score: 0.7984 - val_loss: 0.4273 - val_acc: 0.9895 - val_recall: 0.6527 - val_precision: 0.9232 - val_iou_score: 0.6103\nEpoch 29/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.2062 - acc: 0.9920 - recall: 0.8706 - precision: 0.9730 - iou_score: 0.8051 - val_loss: 0.3811 - val_acc: 0.9895 - val_recall: 0.7188 - val_precision: 0.8929 - val_iou_score: 0.6525\nEpoch 30/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1993 - acc: 0.9920 - recall: 0.8701 - precision: 0.9756 - iou_score: 0.8117 - val_loss: 0.4066 - val_acc: 0.9895 - val_recall: 0.6806 - val_precision: 0.9073 - val_iou_score: 0.6300\nEpoch 31/60\n88/88 [==============================] - 26s 292ms/step - loss: 0.1957 - acc: 0.9920 - recall: 0.8678 - precision: 0.9763 - iou_score: 0.8152 - val_loss: 0.3958 - val_acc: 0.9894 - val_recall: 0.7268 - val_precision: 0.8845 - val_iou_score: 0.6415\nEpoch 32/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1869 - acc: 0.9921 - recall: 0.8773 - precision: 0.9763 - iou_score: 0.8236 - val_loss: 0.3785 - val_acc: 0.9893 - val_recall: 0.7687 - val_precision: 0.8684 - val_iou_score: 0.6579\nEpoch 33/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1878 - acc: 0.9920 - recall: 0.8867 - precision: 0.9725 - iou_score: 0.8231 - val_loss: 0.3960 - val_acc: 0.9893 - val_recall: 0.7354 - val_precision: 0.8771 - val_iou_score: 0.6428\nEpoch 34/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.1878 - acc: 0.9920 - recall: 0.8866 - precision: 0.9712 - iou_score: 0.8233 - val_loss: 0.4028 - val_acc: 0.9891 - val_recall: 0.7389 - val_precision: 0.8657 - val_iou_score: 0.6378\nEpoch 35/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1899 - acc: 0.9919 - recall: 0.8859 - precision: 0.9672 - iou_score: 0.8217 - val_loss: 0.4046 - val_acc: 0.9891 - val_recall: 0.7347 - val_precision: 0.8661 - val_iou_score: 0.6362\nEpoch 36/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.1807 - acc: 0.9920 - recall: 0.8840 - precision: 0.9728 - iou_score: 0.8302 - val_loss: 0.4165 - val_acc: 0.9894 - val_recall: 0.6821 - val_precision: 0.9001 - val_iou_score: 0.6249\nEpoch 37/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.1800 - acc: 0.9920 - recall: 0.8810 - precision: 0.9741 - iou_score: 0.8312 - val_loss: 0.4689 - val_acc: 0.9891 - val_recall: 0.6150 - val_precision: 0.9173 - val_iou_score: 0.5782\nEpoch 38/60\n88/88 [==============================] - 26s 292ms/step - loss: 0.1786 - acc: 0.9921 - recall: 0.8742 - precision: 0.9766 - iou_score: 0.8323 - val_loss: 0.4650 - val_acc: 0.9892 - val_recall: 0.6124 - val_precision: 0.9273 - val_iou_score: 0.5814\nEpoch 39/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1752 - acc: 0.9921 - recall: 0.8710 - precision: 0.9787 - iou_score: 0.8354 - val_loss: 0.4437 - val_acc: 0.9893 - val_recall: 0.6437 - val_precision: 0.9119 - val_iou_score: 0.6011\nEpoch 40/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1771 - acc: 0.9921 - recall: 0.8691 - precision: 0.9769 - iou_score: 0.8339 - val_loss: 0.4162 - val_acc: 0.9890 - val_recall: 0.7228 - val_precision: 0.8619 - val_iou_score: 0.6276\nEpoch 41/60\n88/88 [==============================] - 26s 298ms/step - loss: 0.1715 - acc: 0.9921 - recall: 0.8823 - precision: 0.9753 - iou_score: 0.8392 - val_loss: 0.4215 - val_acc: 0.9889 - val_recall: 0.7291 - val_precision: 0.8576 - val_iou_score: 0.6230\nEpoch 42/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1678 - acc: 0.9921 - recall: 0.8907 - precision: 0.9747 - iou_score: 0.8427 - val_loss: 0.4381 - val_acc: 0.9891 - val_recall: 0.6801 - val_precision: 0.8898 - val_iou_score: 0.6080\nEpoch 43/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.1624 - acc: 0.9921 - recall: 0.8925 - precision: 0.9767 - iou_score: 0.8478 - val_loss: 0.4353 - val_acc: 0.9894 - val_recall: 0.6534 - val_precision: 0.9173 - val_iou_score: 0.6094\nEpoch 44/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1555 - acc: 0.9922 - recall: 0.8865 - precision: 0.9824 - iou_score: 0.8540 - val_loss: 0.4322 - val_acc: 0.9893 - val_recall: 0.6587 - val_precision: 0.9098 - val_iou_score: 0.6123\nEpoch 45/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.1559 - acc: 0.9922 - recall: 0.8826 - precision: 0.9837 - iou_score: 0.8538 - val_loss: 0.4333 - val_acc: 0.9894 - val_recall: 0.6576 - val_precision: 0.9102 - val_iou_score: 0.6122\nEpoch 46/60\n88/88 [==============================] - 26s 292ms/step - loss: 0.1603 - acc: 0.9922 - recall: 0.8779 - precision: 0.9826 - iou_score: 0.8500 - val_loss: 0.4107 - val_acc: 0.9894 - val_recall: 0.6796 - val_precision: 0.9033 - val_iou_score: 0.6316\nEpoch 47/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1582 - acc: 0.9922 - recall: 0.8751 - precision: 0.9832 - iou_score: 0.8519 - val_loss: 0.4138 - val_acc: 0.9894 - val_recall: 0.6872 - val_precision: 0.9008 - val_iou_score: 0.6293\nEpoch 48/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1518 - acc: 0.9922 - recall: 0.8820 - precision: 0.9844 - iou_score: 0.8578 - val_loss: 0.3885 - val_acc: 0.9890 - val_recall: 0.7616 - val_precision: 0.8526 - val_iou_score: 0.6523\nEpoch 49/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1530 - acc: 0.9922 - recall: 0.8910 - precision: 0.9800 - iou_score: 0.8568 - val_loss: 0.3900 - val_acc: 0.9892 - val_recall: 0.7469 - val_precision: 0.8693 - val_iou_score: 0.6533\nEpoch 50/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1476 - acc: 0.9922 - recall: 0.8957 - precision: 0.9826 - iou_score: 0.8619 - val_loss: 0.4364 - val_acc: 0.9893 - val_recall: 0.6510 - val_precision: 0.9183 - val_iou_score: 0.6113\nEpoch 51/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1451 - acc: 0.9923 - recall: 0.8912 - precision: 0.9848 - iou_score: 0.8643 - val_loss: 0.4587 - val_acc: 0.9894 - val_recall: 0.6093 - val_precision: 0.9375 - val_iou_score: 0.5905\nEpoch 52/60\n88/88 [==============================] - 26s 298ms/step - loss: 0.1446 - acc: 0.9923 - recall: 0.8822 - precision: 0.9865 - iou_score: 0.8647 - val_loss: 0.4664 - val_acc: 0.9893 - val_recall: 0.6018 - val_precision: 0.9376 - val_iou_score: 0.5845\nEpoch 53/60\n88/88 [==============================] - 26s 293ms/step - loss: 0.1459 - acc: 0.9923 - recall: 0.8757 - precision: 0.9880 - iou_score: 0.8635 - val_loss: 0.4042 - val_acc: 0.9895 - val_recall: 0.6976 - val_precision: 0.8987 - val_iou_score: 0.6397\nEpoch 54/60\n88/88 [==============================] - 26s 298ms/step - loss: 0.1458 - acc: 0.9923 - recall: 0.8802 - precision: 0.9858 - iou_score: 0.8637 - val_loss: 0.4050 - val_acc: 0.9892 - val_recall: 0.7087 - val_precision: 0.8849 - val_iou_score: 0.6387\nEpoch 55/60\n88/88 [==============================] - 26s 294ms/step - loss: 0.1419 - acc: 0.9923 - recall: 0.8895 - precision: 0.9857 - iou_score: 0.8673 - val_loss: 0.4146 - val_acc: 0.9894 - val_recall: 0.6865 - val_precision: 0.9040 - val_iou_score: 0.6303\nEpoch 56/60\n88/88 [==============================] - 26s 297ms/step - loss: 0.1378 - acc: 0.9923 - recall: 0.8923 - precision: 0.9872 - iou_score: 0.8711 - val_loss: 0.4304 - val_acc: 0.9894 - val_recall: 0.6528 - val_precision: 0.9213 - val_iou_score: 0.6167\nEpoch 57/60\n88/88 [==============================] - 26s 293ms/step - loss: 0.1364 - acc: 0.9923 - recall: 0.8900 - precision: 0.9882 - iou_score: 0.8725 - val_loss: 0.4137 - val_acc: 0.9896 - val_recall: 0.6640 - val_precision: 0.9221 - val_iou_score: 0.6316\nEpoch 58/60\n88/88 [==============================] - 26s 296ms/step - loss: 0.1348 - acc: 0.9923 - recall: 0.8875 - precision: 0.9894 - iou_score: 0.8740 - val_loss: 0.4720 - val_acc: 0.9893 - val_recall: 0.5951 - val_precision: 0.9376 - val_iou_score: 0.5805\nEpoch 59/60\n88/88 [==============================] - 26s 295ms/step - loss: 0.1347 - acc: 0.9923 - recall: 0.8834 - precision: 0.9899 - iou_score: 0.8741 - val_loss: 0.4810 - val_acc: 0.9892 - val_recall: 0.5925 - val_precision: 0.9316 - val_iou_score: 0.5735\nEpoch 60/60\n88/88 [==============================] - 26s 293ms/step - loss: 0.1368 - acc: 0.9923 - recall: 0.8792 - precision: 0.9901 - iou_score: 0.8722 - val_loss: 0.4917 - val_acc: 0.9892 - val_recall: 0.5826 - val_precision: 0.9380 - val_iou_score: 0.5648\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T07:18:42.068434Z",
          "iopub.execute_input": "2021-06-18T07:18:42.068806Z"
        },
        "trusted": true,
        "id": "Cny2q46MB-27",
        "outputId": "9458241c-488f-4597-fe95-d00e5a01e603"
      },
      "source": [
        "    model.fit(train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=30,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks,\n",
        "        shuffle = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/30\n88/88 [==============================] - 27s 308ms/step - loss: 0.1340 - acc: 0.9922 - recall: 0.8868 - precision: 0.9884 - iou_score: 0.8747 - val_loss: 0.4283 - val_acc: 0.9894 - val_recall: 0.6634 - val_precision: 0.9137 - val_iou_score: 0.6205\nEpoch 2/30\n88/88 [==============================] - 26s 295ms/step - loss: 0.1336 - acc: 0.9922 - recall: 0.8865 - precision: 0.9886 - iou_score: 0.8751 - val_loss: 0.4044 - val_acc: 0.9894 - val_recall: 0.7086 - val_precision: 0.8931 - val_iou_score: 0.6414\nEpoch 3/30\n88/88 [==============================] - 26s 296ms/step - loss: 0.1365 - acc: 0.9922 - recall: 0.8869 - precision: 0.9863 - iou_score: 0.8725 - val_loss: 0.3890 - val_acc: 0.9893 - val_recall: 0.7423 - val_precision: 0.8765 - val_iou_score: 0.6553\nEpoch 4/30\n88/88 [==============================] - 26s 294ms/step - loss: 0.1380 - acc: 0.9922 - recall: 0.8871 - precision: 0.9854 - iou_score: 0.8712 - val_loss: 0.4505 - val_acc: 0.9893 - val_recall: 0.6395 - val_precision: 0.9141 - val_iou_score: 0.6006\nEpoch 5/30\n88/88 [==============================] - 26s 300ms/step - loss: 0.1362 - acc: 0.9922 - recall: 0.8888 - precision: 0.9863 - iou_score: 0.8729 - val_loss: 0.4530 - val_acc: 0.9895 - val_recall: 0.6112 - val_precision: 0.9389 - val_iou_score: 0.5980\nEpoch 6/30\n88/88 [==============================] - 26s 296ms/step - loss: 0.1380 - acc: 0.9922 - recall: 0.8875 - precision: 0.9857 - iou_score: 0.8712 - val_loss: 0.5879 - val_acc: 0.9885 - val_recall: 0.4863 - val_precision: 0.9425 - val_iou_score: 0.4846\nEpoch 7/30\n88/88 [==============================] - 26s 297ms/step - loss: 0.1354 - acc: 0.9922 - recall: 0.8874 - precision: 0.9867 - iou_score: 0.8737 - val_loss: 0.5151 - val_acc: 0.9890 - val_recall: 0.5626 - val_precision: 0.9330 - val_iou_score: 0.5460\nEpoch 8/30\n88/88 [==============================] - 26s 293ms/step - loss: 0.1350 - acc: 0.9922 - recall: 0.8854 - precision: 0.9873 - iou_score: 0.8739 - val_loss: 0.4253 - val_acc: 0.9892 - val_recall: 0.6940 - val_precision: 0.8885 - val_iou_score: 0.6236\nEpoch 9/30\n88/88 [==============================] - 26s 295ms/step - loss: 0.1335 - acc: 0.9922 - recall: 0.8856 - precision: 0.9878 - iou_score: 0.8754 - val_loss: 0.4283 - val_acc: 0.9889 - val_recall: 0.7158 - val_precision: 0.8639 - val_iou_score: 0.6219\nEpoch 10/30\n88/88 [==============================] - 26s 294ms/step - loss: 0.1322 - acc: 0.9922 - recall: 0.8875 - precision: 0.9878 - iou_score: 0.8766 - val_loss: 0.4410 - val_acc: 0.9890 - val_recall: 0.6898 - val_precision: 0.8807 - val_iou_score: 0.6115\nEpoch 11/30\n88/88 [==============================] - 26s 295ms/step - loss: 0.1310 - acc: 0.9922 - recall: 0.8903 - precision: 0.9883 - iou_score: 0.8778 - val_loss: 0.4594 - val_acc: 0.9892 - val_recall: 0.6294 - val_precision: 0.9195 - val_iou_score: 0.5956\nEpoch 12/30\n88/88 [==============================] - 26s 294ms/step - loss: 0.1290 - acc: 0.9922 - recall: 0.8911 - precision: 0.9888 - iou_score: 0.8796 - val_loss: 0.4550 - val_acc: 0.9893 - val_recall: 0.6333 - val_precision: 0.9179 - val_iou_score: 0.5992\nEpoch 13/30\n88/88 [==============================] - 26s 294ms/step - loss: 0.1281 - acc: 0.9922 - recall: 0.8885 - precision: 0.9897 - iou_score: 0.8804 - val_loss: 0.4632 - val_acc: 0.9892 - val_recall: 0.6344 - val_precision: 0.9126 - val_iou_score: 0.5932\nEpoch 14/30\n88/88 [==============================] - 26s 295ms/step - loss: 0.1280 - acc: 0.9922 - recall: 0.8872 - precision: 0.9900 - iou_score: 0.8806 - val_loss: 0.4054 - val_acc: 0.9893 - val_recall: 0.7220 - val_precision: 0.8848 - val_iou_score: 0.6433\nEpoch 15/30\n88/88 [==============================] - 26s 296ms/step - loss: 0.1281 - acc: 0.9922 - recall: 0.8883 - precision: 0.9896 - iou_score: 0.8805 - val_loss: 0.4135 - val_acc: 0.9893 - val_recall: 0.6940 - val_precision: 0.9003 - val_iou_score: 0.6362\nEpoch 16/30\n88/88 [==============================] - 26s 295ms/step - loss: 0.1278 - acc: 0.9922 - recall: 0.8910 - precision: 0.9886 - iou_score: 0.8808 - val_loss: 0.4404 - val_acc: 0.9894 - val_recall: 0.6460 - val_precision: 0.9211 - val_iou_score: 0.6133\nEpoch 17/30\n88/88 [==============================] - 26s 292ms/step - loss: 0.1277 - acc: 0.9922 - recall: 0.8921 - precision: 0.9887 - iou_score: 0.8809 - val_loss: 0.4915 - val_acc: 0.9892 - val_recall: 0.5854 - val_precision: 0.9351 - val_iou_score: 0.5702\nEpoch 18/30\n88/88 [==============================] - 26s 296ms/step - loss: 0.1289 - acc: 0.9922 - recall: 0.8903 - precision: 0.9883 - iou_score: 0.8799 - val_loss: 0.4930 - val_acc: 0.9891 - val_recall: 0.5858 - val_precision: 0.9341 - val_iou_score: 0.5686\nEpoch 19/30\n88/88 [==============================] - 26s 296ms/step - loss: 0.1295 - acc: 0.9922 - recall: 0.8874 - precision: 0.9889 - iou_score: 0.8794 - val_loss: 0.4897 - val_acc: 0.9891 - val_recall: 0.5988 - val_precision: 0.9234 - val_iou_score: 0.5720\nEpoch 20/30\n88/88 [==============================] - 26s 297ms/step - loss: 0.1307 - acc: 0.9922 - recall: 0.8869 - precision: 0.9881 - iou_score: 0.8783 - val_loss: 0.4921 - val_acc: 0.9890 - val_recall: 0.6110 - val_precision: 0.9090 - val_iou_score: 0.5695\nEpoch 21/30\n88/88 [==============================] - 26s 296ms/step - loss: 0.1344 - acc: 0.9922 - recall: 0.8862 - precision: 0.9861 - iou_score: 0.8748 - val_loss: 0.5507 - val_acc: 0.9886 - val_recall: 0.5501 - val_precision: 0.9117 - val_iou_score: 0.5205\nEpoch 22/30\n88/88 [==============================] - 26s 298ms/step - loss: 0.1391 - acc: 0.9921 - recall: 0.8865 - precision: 0.9825 - iou_score: 0.8706 - val_loss: 0.4564 - val_acc: 0.9892 - val_recall: 0.6338 - val_precision: 0.9101 - val_iou_score: 0.6014\nEpoch 23/30\n88/88 [==============================] - 27s 300ms/step - loss: 0.1327 - acc: 0.9922 - recall: 0.8879 - precision: 0.9862 - iou_score: 0.8765 - val_loss: 0.4430 - val_acc: 0.9895 - val_recall: 0.6340 - val_precision: 0.9285 - val_iou_score: 0.6115\nEpoch 24/30\n88/88 [==============================] - 26s 294ms/step - loss: 0.1265 - acc: 0.9922 - recall: 0.8890 - precision: 0.9899 - iou_score: 0.8822 - val_loss: 0.4337 - val_acc: 0.9895 - val_recall: 0.6473 - val_precision: 0.9267 - val_iou_score: 0.6197\nEpoch 25/30\n88/88 [==============================] - 26s 298ms/step - loss: 0.1232 - acc: 0.9923 - recall: 0.8892 - precision: 0.9911 - iou_score: 0.8852 - val_loss: 0.4418 - val_acc: 0.9894 - val_recall: 0.6538 - val_precision: 0.9157 - val_iou_score: 0.6143\nEpoch 26/30\n88/88 [==============================] - 26s 295ms/step - loss: 0.1213 - acc: 0.9923 - recall: 0.8909 - precision: 0.9915 - iou_score: 0.8869 - val_loss: 0.4353 - val_acc: 0.9894 - val_recall: 0.6659 - val_precision: 0.9123 - val_iou_score: 0.6202\nEpoch 27/30\n88/88 [==============================] - 26s 297ms/step - loss: 0.1186 - acc: 0.9923 - recall: 0.8908 - precision: 0.9925 - iou_score: 0.8895 - val_loss: 0.4126 - val_acc: 0.9896 - val_recall: 0.6815 - val_precision: 0.9141 - val_iou_score: 0.6390\nEpoch 28/30\n88/88 [==============================] - 26s 294ms/step - loss: 0.1178 - acc: 0.9923 - recall: 0.8934 - precision: 0.9923 - iou_score: 0.8902 - val_loss: 0.4445 - val_acc: 0.9894 - val_recall: 0.6365 - val_precision: 0.9292 - val_iou_score: 0.6117\nEpoch 29/30\n88/88 [==============================] - 26s 297ms/step - loss: 0.1165 - acc: 0.9923 - recall: 0.8944 - precision: 0.9928 - iou_score: 0.8914 - val_loss: 0.4537 - val_acc: 0.9894 - val_recall: 0.6257 - val_precision: 0.9257 - val_iou_score: 0.6040\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FKCxG8d1B-28"
      },
      "source": [
        "import os\n",
        "  \n",
        "# Directory\n",
        "directory = \"RESULT_DenseNet210WithDropout\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"./\"\n",
        "  \n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "# Create the directory\n",
        "# 'GeeksForGeeks' in\n",
        "# '/home / User / Documents'\n",
        "os.mkdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BE1T2q-zB-29"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tqdm import tqdm\n",
        "#from data import load_data, tf_dataset\n",
        "#from train import iou\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (256, 256))\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (256, 256))\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)\n",
        "    mask = [mask, mask, mask]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    return mask\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ## Dataset\n",
        "    \n",
        "    batch_size = 8\n",
        "    #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(\"/content/drive/MyDrive/Test\")\n",
        "\n",
        "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
        "\n",
        "    test_steps = (len(test_x)//batch_size)\n",
        "    if len(test_x) % batch_size != 0:\n",
        "        test_steps += 1\n",
        "\n",
        "    #with CustomObjectScope({'iou': iou}):\n",
        "    #    model = tf.keras.models.load_model(\"/content/drive/model.h5\")\n",
        "\n",
        "    #model.evaluate(test_dataset, steps=test_steps)\n",
        "\n",
        "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
        "        h, w, _ = x.shape\n",
        "        white_line = np.ones((h, 10, 3)) * 255.0\n",
        "\n",
        "        all_images = [\n",
        "            x * 255.0, white_line,\n",
        "            mask_parse(y), white_line,\n",
        "            mask_parse(y_pred) * 255.0\n",
        "        ]\n",
        "        image = np.concatenate(all_images, axis=1)\n",
        "        \n",
        "        cv2.imwrite(f\"./RESULT_DenseNet210WithDropout/{i}.png\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9E-Bgu2NB-29"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}